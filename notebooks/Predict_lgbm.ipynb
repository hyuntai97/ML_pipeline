{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_pipeline_lgbm.yml\n",
    "\n",
    "# seed: 42\n",
    "# TRAIN:\n",
    "#     train_SN: \n",
    "# MODEL:\n",
    "#     model_nm: 'LGBM'\n",
    "# PREDICT:\n",
    "#     threshold: 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml \n",
    "# import os, sys\n",
    "# import glob\n",
    "# from shutil import copyfile\n",
    "# import json \n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report, roc_auc_score, log_loss, \n",
    "# precision_recall_curve, auc, precision_score, recall_score\n",
    "# from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# import matplotlib as mpl \n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(filepath, imagename):\n",
    "    filename = f'{filepath}{imagename}.png'\n",
    "    print('Saving data to: ', filename)\n",
    "    \n",
    "    files_present = glob.glob(filename)\n",
    "    if not files_present:\n",
    "        plt.savefig(filename, dpi=100, bbox_inches='tight')\n",
    "        print('Export complete')\n",
    "    else:\n",
    "        print('WARNINGS: This image file already exists')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_curve_plot(y_test, pred_proba):\n",
    "    precision, recall, threshold = precision_recall_curve(y_test, pred_proba)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = threshold.shape[0]\n",
    "    plt.plot(threshold, precision[0: threshold_boundary], linestyle='--',label='precision')\n",
    "    plt.plot(threshold, recall[0: threshold_boundary], label='recall')\n",
    "    \n",
    "    stard, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(stard, end, 0.1), 2))\n",
    "    \n",
    "    plt.xlabel('Threshold value')\n",
    "    plt.ylabel('Precision and Recall value')\n",
    "    plt.legend()\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ = '__main__':\n",
    "#     PRJ_DIR = '/workspace/malware/'\n",
    "#     sys.path.append(PRJ_DIR)\n",
    "    \n",
    "#     from modules.utils import generate_serial_number, load_object\n",
    "#     from modules.utils import make_local_importance, make_local_importance2\n",
    "#     from modules.metric import *\n",
    "    \n",
    "#     CONFIG_PATH = f'{PRJ_DIR}config/predict_pipeline_lgbm.yml'\n",
    "#     with open(CONFIG_PATH, 'r') as f:\n",
    "#         config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "#     SEED = config['seed']\n",
    "#     DATA_DIR = f'{PRJ_DIR}data/01_preprocessing/'\n",
    "#     TRAIN_SN = config['TRAIN']['train_SN']\n",
    "#     print(f'Train SN: {TRAIN_SN}')\n",
    "    \n",
    "#     MODEL_DIR = f'{PRJ_DIR}/results/train/{TRAIN_SN}/'\n",
    "    \n",
    "#     SN = generate_serial_number()\n",
    "#     PREDICT_DR = f'{PRJ_DIR}/results/predict/{TRAIN_SN}_{SN}/'\n",
    "#     os.makedirs(PREDICT_DR, exist_ok=True)\n",
    "    \n",
    "#     copyfile(CONFIG_PATH, f'{PREDICT_DR}/pred_config_copy.yml')\n",
    "    \n",
    "#     TRAIN_CONFIG_PATH = f'{PRJ_DIR}config/train_pipeline_lgbm.yml'\n",
    "#     with open(TRAIN_CONFIG_PATH, 'r') as f:\n",
    "#         tr_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "#     use_col = tr_config['DATA']['use_features']\n",
    "#     DATA_SN = tr_config['DATA']['data_SN']\n",
    "    \n",
    "#     Xtest_file = 'X_test'\n",
    "#     ytest_file = 'y_test'\n",
    "#     Xtrain_file = 'X_train'\n",
    "#     ytrain_file = 'y_train'\n",
    "#     Xvalid_file = 'X_valid'\n",
    "#     yvalid_file = 'y_valid'\n",
    "    \n",
    "#     X_test = pd.read_feather(f'{DATA_DIR}{DATA_SN}/{Xtest_file}.ftr')\n",
    "#     X_test = X_test[use_col]\n",
    "#     y_test = pd.read_feather(f'{DATA_DIR}{DATA_SN}/{ytest_file}.ftr')\n",
    "    \n",
    "#     X_train = pd.read_feather(f'{DATA_DIR}{DATA_SN}/{Xtrain_file}.ftr')\n",
    "#     X_train = X_train[use_col]\n",
    "#     y_train = pd.read_feather(f'{DATA_DIR}{DATA_SN}/{ytrain_file}.ftr')\n",
    "    \n",
    "#     X_valid = pd.read_feather(f'{DATA_DIR}{DATA_SN}/{Xvalid_file}.ftr')\n",
    "#     X_valid = X_valid[use_col]\n",
    "#     y_valid = pd.read_feather(f'{DATA_DIR}{DATA_SN}/{yvalid_file}.ftr')\n",
    "    \n",
    "#     X_test_origin = X_test.copy()\n",
    "\n",
    "#     cat_lst = tr_config['DATA']['cat_features']\n",
    "#     for c in cat_lst:\n",
    "#         X_train[c] = X_train[c].astype('category')\n",
    "#         X_valid[c] = X_valid[c].astype('category')\n",
    "#         X_test[c] = X_test[c].astype('category')\n",
    "        \n",
    "#     model = load_object(MODEL_DIR, TRAIN_SN)\n",
    "    \n",
    "#     THRESHOLD = config['PREDICT']['threshold']\n",
    "#     b = Binarizer(threshold=THRESHOLD)\n",
    "    \n",
    "#     y_pred_proba = model.predict(X_test)\n",
    "#     y_pred = b.fit_transform(y_pred_proba.reshape(-1, 1))\n",
    "#     accuracy = accuracy_score(y_test['악성코드여부'], y_pred)\n",
    "#     roc = auroc(np.array(y_test['악성코드여부']), y_pred_proba)\n",
    "    \n",
    "#     cm = confusion_matrix(y_test['악성코드여부'], y_pred)\n",
    "#     cm_matrix = pd.DataFrame(data=cm, columns=['Predict Negatives: 0', 'Predict Positives: 1']\n",
    "#                              ,index=['Actual Negatives:0', 'Actual Positives:1'])\n",
    "#     sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "#     mpl.rcParams['font.family'] = 'KBFG Text'\n",
    "#     save_image(PREDICT_DR, 'cm_'+MODELNM)\n",
    "    \n",
    "#     print(classification_report(y_test['악성코드여부'], y_pred))\n",
    "    \n",
    "#     prec = precision_score(y_test['악성코드여부'], y_pred)\n",
    "#     rec = recall_score(y_test['악성코드여부'], y_pred)\n",
    "#     f1score = f1_score(y_test['악성코드여부'], y_pred)\n",
    "#     precision_recall_curve_plot(y_test['악성코드여부'], y_pred_proba)\n",
    "#     save_image(PREDICT_DR, 'prc_'+TRAIN_SN)\n",
    "    \n",
    "#     metric_dic = {}\n",
    "#     metric_dic['data_serial_num'] = tr_config['DATA']['data_SN']\n",
    "#     metric_dic['train_serial_num'] = config['TRAIN']['train_SN']\n",
    "    \n",
    "#     metric_dic['test_accuracy'] = accuracy\n",
    "#     metric_dic['test_f1_score'] = f1score\n",
    "#     metric_dic['test_precision'] = prec\n",
    "#     metric_dic['test_auroc'] = roc\n",
    "#     metric_dic['test_loss'] = log_loss(y_test['악성코드여부'], y_pred)\n",
    "    \n",
    "#     metric_df = pd.DataFrame.from_dict(metric_dic, orient='index').T\n",
    "#     metric_df_train = pd.read_csv(f'{MODEL_DIR}/metric_df_train.csv')\n",
    "#     metric_df = pd.concat([metric_df, metric_df_train], axis=1)\n",
    "#     metric_df.to_csv(f'{PREDICT_DR}/metric_df.csv', index=False)\n",
    "    \n",
    "#     df = pd.concat([y_test, X_test_origin], axis=1)\n",
    "#     df['예측'] = y_pred\n",
    "#     df['예측proba'] = y_pred_proba\n",
    "    \n",
    "#     print('====complete====')\n",
    "\n",
    "#     explainer = shap.TreeExplainer(model)\n",
    "#     shap_values = explainer.shap_values(X_test)\n",
    "    \n",
    "#     shap_matrix = shap_values[1]\n",
    "#     shap_matrix = np.round_(shap_matrix, 4)\n",
    "    \n",
    "#     shap_columns = []\n",
    "#     for col in X_test.columns:\n",
    "#         shap_columns.append(f'(SHAP){col}')\n",
    "        \n",
    "#     shap_df = pd.DataFrame(shap_matrix, columns=shap_columns)\n",
    "#     df = pd.concat([df, shap_df], axis=1)\n",
    "    \n",
    "#     df.to_csv(f'{PREDICT_DR}{TRAIN_SN}.csv', encoding='utf-8-sig', index=False)\n",
    "    \n",
    "#     local_importance_dic = make_local_importance(df)\n",
    "    \n",
    "#     with open(f'{PREDICT_DR}/local_shap.json', 'w') as f:\n",
    "#         json.dump(local_importance_dic, f, ensure_ascii=False)\n",
    "        \n",
    "#     df_add_shap = make_local_importance2(df)\n",
    "#     df_add_shap.to_csv(f'{PREDICT_DR}/shap_local_add.csv', encoding='utf-8-sig',index=False)\n",
    "    \n",
    "#     fig = shap.summary_plot(shap_matrix, X_test, show=False)\n",
    "#     plt.savefig(f'{PREDICT_DR}shap.jpg', dpi=100, bbox_inches='tight')\n",
    "#     plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
